---
title: "Is reproducibility good enough?"
author: "Harald Bjarne Vika"
date: last-modified
date-format: "18,09,2025"
csl: apa7.csl
lang: en-GB
format:
  html: default
  typst:
    papersize: a4
  pdf:
    documentclass: article
    number-sections: true
    keep-tex: true
    papersize: A4
    fig-pos: "H"
bibliography: reproducibility.bib
abstract: "A very short abstract. Put the abstract text here. One or two paragraphs summarising what follows below."
---

## Introduction

What is this paper about?
What is discussed?
Why is it of any consequence?

The advancement of science is build on a trust in discovery of new data, and through the use of reproducibility, scientist can gain confidence in their research concluded data.
But in recent time, the community have been getting reports on more peer-reviewed preclinical studies that are none reproducible[@mcnutt2014].

In this paper we will look more in to reproducibility of scientific data, why its important for using to gaining trust and if its good enough to be consider useful for the future scientist to use.
The paper will first present literature around the meaning of word reproducibility and replicate, and its use in the science world.
We will then discuss if reproducibility is necessary or if the scientific data can be replicated.
How the use of R and a quarto document can help with reproducibility of research, any problems that can which may occur and if we can solve them.
In the need we will try to conclude these questions and what our thoughts on the subject of reproducibility of scientific data.

## Literature review

## Theory on reproducibility

Smart stuff from others about the topic.

The cover story of The Economist "How Science goes wrong" uses the terms for reproducibility from [@barbaTerminologiesReproducibleResearch2018] which is "*Reproducibility refers to the instance in which the original researcher's data and computer codes are used to regenerate the results, and arriving at the same results using their own data and methods*".
While from the same review paper the term of replicability can viewed as an "*instances in which a researcher collects new data to arrive at the same scientific findings as a previous study,"* or *"a different team arriving at the same results using the original authors artifacts".* With this we have a understanding that the terms of reproducibility and replicability can overlap one another but can be used differently.
Another term is generalizability, where the results of a study can be applied on any other context or population which is different from the original case study.
These three terms would refers to the science that is "robust and reliable" which is the foundation of all scientific development for the ability to build on prior work.
Here we will try to focus on the use of reproducibility of scientific data.

The reproducibility is a necessary, but not sufficient condition for replicability.
@peng2011 Discusses that reproducibility for a publication should be a minimal requirement.
As said earlier that reproducibility is a way for the scientist to gain confident and trust in their research but what is a research reproducibility?
@goodman2016b gives us three explanations of what research reproducibiliy means:

-   Methods reproducibility, which is how the provision of enough detail about study procedures and data can be used to repeat the same research in theory and in actuality.

-   Results reproducibility, also described as replicabilty, is refereed to obtain the same results from previously research when conducting independent studies but the process is the same as the original research.

-   Robustness and generalizability are two terms that can be used instead of the term reproducibility, where robustness means the stability of a experimental conclusion when it is either a baseline assumptions or experimental procedures.
    Generalizability can be refereed to the persistence of an effect in settings different from and outside of experimental framework.

## Publication bias

When it comes to publication on reproducibility one can encounter publication bias which may affect the ability to publish the findings.
The worst case if a scientific journals contains a big collection of the type 1 error.
So what is type 1 error?
Its the definition of a incorrectly concluding of the research[@TypeTypeII].
Its the size of the error which the researcher is willing to accept prior to the hypothesis test.
Type 1 error is when H0 is rejected even if its true.
It can be about concluding that there is an effect even when its not.
This way we may end up with similar studies with no effect but there can be a risk that we would find the wrong conclusion in the literature.
This will hurt later research that tries to replicate the experiment.
An exempel on this is the "File Drawer Problem" from @rosenthal1979, where studies with an H0 that can not be rejected is sent to the file drawer and the ones where H0 is rejected is published.
This will go on to create false positive.
If prestigious journals manage to publish an research with a false positive it will make it so that others will have little motivation to try to reproduce it.
Another error that can occur is that its costly to invest in a research program which in the end will create more false positive and may lead to ineffective policy changes.
A field that is known to publish research with false positive would surly risk losing its credibility and trust from other scientist [@simmons2011].
The @young2008 tells that its "*more alarming is the general paucity in the literature of negative data. In some fields, almost all published studies sow formally significant results so that statistical significance no longer appears discriminating*".
The publication bias will also have effect on meta-analysis, which is an combined result of multiple scientific studies[@russoHowReviewMetaanalysis2007].
So when one result is influenced by publication bias, the others may feel its effect.

So when it comes it economic and how to be able to reproduce the research, one can look at an old journal the "Econometrica" where @frischEditorsNote1933 states that "*Statistical and other numerical work presented in Econometrica, the original raw data will, as a rule, be published, unless their volume is excessive*".
This states that all the data ones used in its research should be presented if possible.
But as time passes, bigger models was needed to present the data which ended up in researchers only publicing the results and the reproducing or replicating of the research ended up nearly impossible.
Solutions had to be created for archiving the data, one was the American Economic Association data archive[@zotero-321].
@mccullough2008a points that "*All the long-standing archives at economics journals do not facilitate the re-production of published results. The data-only archives at Journal of business and Economic Statistics and Economic Journal fail in part because most authors do not contribute data*".
With other words, the solution didn't work as one hoped for.
Another solution is the "computable documents" solution that uses codes integral in the article, so that the research can be submitted with the data necessary to fully be able to reproduce the research.
Through the use of codes one could reproduce research that used more and larger data then before.
One exempel on "computable documents" could be Wavelab which is a computer package that contains all the codes one require to reproduce figures from the researchers published wavelet articles.
This package comes from @WaveLabReproducibleResearch, where they want people that's interested to inspect the source codes so that scientist could be more engage in "really reproducible" research.
A quote from @gentleman2007b tells us how a software tool should be of assisten when it comes to reproducibility: "*The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the methods that are presented in the research paper*."

Use a least 20 citations, a least 5 of them must be new (not from the provided .bib file).

Use both in-line and normal citations.

Example:

@gentleman2005 argues that bla bla bla.
On the other hand it's claimed that bla bla [@barbalorenaa.2018; @bartlett2008].

## Discussion of the reseach question

-   Should replicability be the norm or is this to much to ask for now?
-   Can Quarto documents help with reproducibility?
-   What problems remains and how can these be solved?

## Conclusion

## References

and

-   Version number and reference to packages used
-   R version used
